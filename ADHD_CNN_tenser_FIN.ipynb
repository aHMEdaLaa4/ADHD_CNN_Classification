{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f732c44f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import scipy.io\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import mne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b52c7327",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ADHD_data_path='Dataset_proc/ADHD_full'\n",
    "Control_data_path='Dataset_proc/Control_full'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77eae1df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convertmat2mne(data):\n",
    "    ch_names =  ['Fp1', 'Fp2', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4', 'O1', 'O2','F7','F8','T7','T8','P7','P8','Fz','Cz','Pz']\n",
    "    ch_types = ['eeg'] * 19\n",
    "    sampling_freq=128\n",
    "    info = mne.create_info(ch_names, ch_types=ch_types, sfreq=sampling_freq)\n",
    "    #info.set_montage('standard_1020')\n",
    "    data=mne.io.RawArray(data, info)\n",
    "    data.set_eeg_reference()\n",
    "    data.filter(l_freq=1,h_freq=35)\n",
    "    epochs=mne.make_fixed_length_epochs(data,duration=3.5,overlap=0)\n",
    "    return epochs.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c983cbb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "ADHD_subject=[]\n",
    "for AD in glob(ADHD_data_path + '/*.mat'):\n",
    "    try:\n",
    "        mat_data = scipy.io.loadmat(AD, squeeze_me=True, struct_as_record=False)\n",
    "        for key in mat_data.keys():\n",
    "            if not key.startswith('__'):\n",
    "                data = mat_data[key]\n",
    "                data=np.transpose(data)\n",
    "                data=convertmat2mne(data)\n",
    "                ADHD_subject.append(data)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading file {AD}: {e}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0d8a042",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "Control_subject=[]\n",
    "for CO in glob(Control_data_path + '/*.mat'):\n",
    "    try:\n",
    "        mat_data = scipy.io.loadmat(CO, squeeze_me=True, struct_as_record=False)\n",
    "        for key in mat_data.keys():\n",
    "            if not key.startswith('__'):\n",
    "                data = mat_data[key]\n",
    "                data=np.transpose(data)\n",
    "                data=convertmat2mne(data)\n",
    "                Control_subject.append(data)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading file {CO}: {e}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a9e2b2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61, 60)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ADHD_subject),len(Control_subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d69e6cc2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61 60\n"
     ]
    }
   ],
   "source": [
    "ADHD_epochs_labels=[len(i)*[1] for i in ADHD_subject]\n",
    "Control_epochs_labels=[len(i)*[0] for i in Control_subject]\n",
    "print(len(ADHD_epochs_labels),len(Control_epochs_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20073eed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121 121 121\n"
     ]
    }
   ],
   "source": [
    "data_list=ADHD_subject+Control_subject\n",
    "label_list=ADHD_epochs_labels+Control_epochs_labels\n",
    "\n",
    "groups_list=[[i]*len(j) for i, j in enumerate(data_list)]\n",
    "'''\n",
    "Subject1:\n",
    "-epoch0\n",
    "-epoch1\n",
    "-epoch2\n",
    "Subject2:\n",
    "-epoch0\n",
    "-epoch1\n",
    "-epoch2\n",
    "_________\n",
    "Train\n",
    "Subject1:\n",
    "-epoch0\n",
    "                                            Testيبقى تبع ال Subjectتاني لنفس ال epoch و Tain معين يبقى تبع Subjectل epoch يحصل ان Split ممكن و انا بعمل\n",
    "                         و دي حاجة انا مش عاوزها        \n",
    "                                        \n",
    "                                                \n",
    "Test\n",
    "Subject1:\n",
    "-epoch1\n",
    "_________\n",
    "Train\n",
    "Subject1:\n",
    "-epoch0\n",
    "-epoch1\n",
    "-epoch2                               \n",
    "\n",
    "                                                          Test او Train تبقى تبع  Subjectلنفس ال epochsبحيث ان كل ال   Groupsل  DATAف انا قسمت ال \n",
    "Test\n",
    "Subject2:\n",
    "-epoch0\n",
    "-epoch1\n",
    "-epoch2\n",
    "\n",
    "\n",
    "'''\n",
    "print(len(data_list),len(label_list),len(groups_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfd83c73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold,LeaveOneGroupOut\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "gkf=GroupKFold()\n",
    "from sklearn.base import TransformerMixin,BaseEstimator\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#https://stackoverflow.com/questions/50125844/how-to-standard-scale-a-3d-matrix\n",
    "class StandardScaler3D(BaseEstimator,TransformerMixin):\n",
    "    #batch, sequence, channels\n",
    "    def __init__(self):\n",
    "        self.scaler = StandardScaler()\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        self.scaler.fit(X.reshape(-1, X.shape[2]))\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):\n",
    "        return self.scaler.transform(X.reshape( -1,X.shape[2])).reshape(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "378fe005",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4770, 448, 19) (4770,) (4770,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "data_array=np.concatenate(data_list)\n",
    "label_array=np.concatenate(label_list)\n",
    "group_array=np.concatenate(groups_list)\n",
    "data_array=np.moveaxis(data_array,1,2)\n",
    "\n",
    "print(data_array.shape,label_array.shape,group_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "158efd0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracy=[]\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(data_array, label_array, groups=group_array)):\n",
    "    train_features, val_features = data_array[train_index], data_array[val_index]\n",
    "    train_labels, val_labels = label_array[train_index], label_array[val_index]\n",
    "    scaler=StandardScaler3D()\n",
    "    train_features=scaler.fit_transform(train_features)\n",
    "    val_features=scaler.transform(val_features)\n",
    "    break\n",
    "    '''\n",
    "# Save X_train\n",
    "np.save('train_features.npy', train_features)\n",
    "# Save y_train\n",
    "np.save('train_labels.npy', train_labels)\n",
    "# Save X_test\n",
    "np.save('val_features.npy', val_features)\n",
    "# Save y_test\n",
    "np.save('val_labels.npy', val_labels)    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "742cf534-13a7-4c6d-9c21-99e2e8a2282c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# In subsequent runs\n",
    "train_features = np.load('train_features.npy')\n",
    "train_labels = np.load('train_labels.npy')\n",
    "val_features = np.load('val_features.npy')\n",
    "val_labels = np.load('val_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8bebf16d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3816,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf91d8dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input,Dense,concatenate,Flatten,GRU,Conv1D\n",
    "from tensorflow.keras.models import Model\n",
    "#resource:https://github.com/dll-ncai/eeg_pre-diagnostic_screening/blob/master/code/chrononet/chrono.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "006f87a7-b307-4a67-bc3c-02819b8ea3d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 448, 64)           3712      \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 448, 64)           256       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 448, 64)           12352     \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 448, 64)           256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1  (None, 224, 64)           0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 224, 128)          24704     \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 224, 128)          512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 224, 128)          49280     \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 224, 128)          512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPoolin  (None, 112, 128)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " global_average_pooling1d (  (None, 128)               0         \n",
      " GlobalAveragePooling1D)                                         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 91713 (358.25 KB)\n",
      "Trainable params: 90945 (355.25 KB)\n",
      "Non-trainable params: 768 (3.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv1D,BatchNormalization,LeakyReLU,MaxPool1D,\\\n",
    "GlobalAveragePooling1D,Dense,Dropout,AveragePooling1D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.backend import clear_session\n",
    "def cnnmodel():\n",
    "    clear_session()\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Block 1\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, strides=1, padding='same', activation='relu', input_shape=(448, 19)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool1D(pool_size=2, strides=2))\n",
    "\n",
    "    # Block 2\n",
    "    model.add(Conv1D(filters=128, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv1D(filters=128, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool1D(pool_size=2, strides=2))\n",
    "\n",
    "\n",
    "\n",
    "    model.add(GlobalAveragePooling1D())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model=cnnmodel()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "db0c0a7d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "96/96 [==============================] - 5s 43ms/step - loss: 0.4088 - accuracy: 0.8118 - val_loss: 0.5319 - val_accuracy: 0.7526\n",
      "Epoch 2/60\n",
      "96/96 [==============================] - 4s 44ms/step - loss: 0.2435 - accuracy: 0.8981 - val_loss: 0.2959 - val_accuracy: 0.8795\n",
      "Epoch 3/60\n",
      "96/96 [==============================] - 4s 42ms/step - loss: 0.1698 - accuracy: 0.9345 - val_loss: 0.1860 - val_accuracy: 0.9329\n",
      "Epoch 4/60\n",
      "96/96 [==============================] - 4s 40ms/step - loss: 0.1414 - accuracy: 0.9463 - val_loss: 0.1897 - val_accuracy: 0.9235\n",
      "Epoch 5/60\n",
      "96/96 [==============================] - 4s 42ms/step - loss: 0.1142 - accuracy: 0.9536 - val_loss: 0.1250 - val_accuracy: 0.9528\n",
      "Epoch 6/60\n",
      "96/96 [==============================] - 4s 43ms/step - loss: 0.0895 - accuracy: 0.9670 - val_loss: 0.2153 - val_accuracy: 0.9130\n",
      "Epoch 7/60\n",
      "96/96 [==============================] - 4s 43ms/step - loss: 0.0753 - accuracy: 0.9746 - val_loss: 0.1077 - val_accuracy: 0.9560\n",
      "Epoch 8/60\n",
      "96/96 [==============================] - 4s 41ms/step - loss: 0.0574 - accuracy: 0.9817 - val_loss: 0.0915 - val_accuracy: 0.9623\n",
      "Epoch 9/60\n",
      "96/96 [==============================] - 4s 43ms/step - loss: 0.0653 - accuracy: 0.9780 - val_loss: 0.2714 - val_accuracy: 0.9057\n",
      "Epoch 10/60\n",
      "96/96 [==============================] - 4s 44ms/step - loss: 0.0520 - accuracy: 0.9817 - val_loss: 0.1612 - val_accuracy: 0.9350\n",
      "Epoch 11/60\n",
      "96/96 [==============================] - 4s 43ms/step - loss: 0.0677 - accuracy: 0.9746 - val_loss: 0.1540 - val_accuracy: 0.9423\n",
      "Epoch 12/60\n",
      "96/96 [==============================] - 4s 40ms/step - loss: 0.0256 - accuracy: 0.9921 - val_loss: 0.1272 - val_accuracy: 0.9539\n",
      "Epoch 13/60\n",
      "96/96 [==============================] - 4s 44ms/step - loss: 0.0308 - accuracy: 0.9903 - val_loss: 0.0879 - val_accuracy: 0.9633\n",
      "Epoch 14/60\n",
      "96/96 [==============================] - 4s 44ms/step - loss: 0.0325 - accuracy: 0.9895 - val_loss: 0.0919 - val_accuracy: 0.9654\n",
      "Epoch 15/60\n",
      "96/96 [==============================] - 4s 43ms/step - loss: 0.0333 - accuracy: 0.9866 - val_loss: 0.1528 - val_accuracy: 0.9486\n",
      "Epoch 16/60\n",
      "96/96 [==============================] - 4s 41ms/step - loss: 0.0438 - accuracy: 0.9830 - val_loss: 0.1499 - val_accuracy: 0.9507\n",
      "Epoch 17/60\n",
      "96/96 [==============================] - 4s 44ms/step - loss: 0.0419 - accuracy: 0.9845 - val_loss: 0.0886 - val_accuracy: 0.9696\n",
      "Epoch 18/60\n",
      "96/96 [==============================] - 4s 44ms/step - loss: 0.0456 - accuracy: 0.9814 - val_loss: 0.0920 - val_accuracy: 0.9654\n",
      "Epoch 19/60\n",
      "96/96 [==============================] - 4s 46ms/step - loss: 0.0191 - accuracy: 0.9948 - val_loss: 0.0890 - val_accuracy: 0.9696\n",
      "Epoch 20/60\n",
      "96/96 [==============================] - 4s 42ms/step - loss: 0.0268 - accuracy: 0.9900 - val_loss: 0.1130 - val_accuracy: 0.9654\n",
      "Epoch 21/60\n",
      "96/96 [==============================] - 4s 44ms/step - loss: 0.0157 - accuracy: 0.9950 - val_loss: 0.1270 - val_accuracy: 0.9518\n",
      "Epoch 22/60\n",
      "96/96 [==============================] - 4s 44ms/step - loss: 0.0390 - accuracy: 0.9861 - val_loss: 0.1168 - val_accuracy: 0.9570\n",
      "Epoch 23/60\n",
      "96/96 [==============================] - 4s 42ms/step - loss: 0.0188 - accuracy: 0.9932 - val_loss: 0.1052 - val_accuracy: 0.9549\n",
      "Epoch 24/60\n",
      "96/96 [==============================] - 4s 43ms/step - loss: 0.0090 - accuracy: 0.9979 - val_loss: 0.0830 - val_accuracy: 0.9696\n",
      "Epoch 25/60\n",
      "96/96 [==============================] - 4s 45ms/step - loss: 0.0078 - accuracy: 0.9979 - val_loss: 0.1336 - val_accuracy: 0.9570\n",
      "Epoch 26/60\n",
      "96/96 [==============================] - 4s 45ms/step - loss: 0.0251 - accuracy: 0.9916 - val_loss: 0.1609 - val_accuracy: 0.9539\n",
      "Epoch 27/60\n",
      "96/96 [==============================] - 4s 43ms/step - loss: 0.0265 - accuracy: 0.9916 - val_loss: 0.1017 - val_accuracy: 0.9665\n",
      "Epoch 28/60\n",
      "96/96 [==============================] - 4s 44ms/step - loss: 0.0130 - accuracy: 0.9955 - val_loss: 0.0775 - val_accuracy: 0.9706\n",
      "Epoch 29/60\n",
      "96/96 [==============================] - 4s 46ms/step - loss: 0.0112 - accuracy: 0.9961 - val_loss: 0.0943 - val_accuracy: 0.9675\n",
      "Epoch 30/60\n",
      "96/96 [==============================] - 5s 48ms/step - loss: 0.0165 - accuracy: 0.9932 - val_loss: 0.1477 - val_accuracy: 0.9518\n",
      "Epoch 31/60\n",
      "96/96 [==============================] - 4s 43ms/step - loss: 0.0172 - accuracy: 0.9932 - val_loss: 0.0955 - val_accuracy: 0.9686\n",
      "Epoch 32/60\n",
      "96/96 [==============================] - 4s 47ms/step - loss: 0.0234 - accuracy: 0.9914 - val_loss: 0.1817 - val_accuracy: 0.9413\n",
      "Epoch 33/60\n",
      "96/96 [==============================] - 5s 48ms/step - loss: 0.0164 - accuracy: 0.9950 - val_loss: 0.0826 - val_accuracy: 0.9717\n",
      "Epoch 34/60\n",
      "96/96 [==============================] - 4s 43ms/step - loss: 0.0226 - accuracy: 0.9919 - val_loss: 0.1474 - val_accuracy: 0.9623\n",
      "Epoch 35/60\n",
      "96/96 [==============================] - 4s 42ms/step - loss: 0.0133 - accuracy: 0.9958 - val_loss: 0.1496 - val_accuracy: 0.9581\n",
      "Epoch 36/60\n",
      "96/96 [==============================] - 4s 45ms/step - loss: 0.0257 - accuracy: 0.9908 - val_loss: 0.0876 - val_accuracy: 0.9727\n",
      "Epoch 37/60\n",
      "96/96 [==============================] - 4s 44ms/step - loss: 0.0223 - accuracy: 0.9911 - val_loss: 0.0814 - val_accuracy: 0.9748\n",
      "Epoch 38/60\n",
      "96/96 [==============================] - 4s 43ms/step - loss: 0.0102 - accuracy: 0.9969 - val_loss: 0.1502 - val_accuracy: 0.9497\n",
      "Epoch 39/60\n",
      "96/96 [==============================] - 4s 43ms/step - loss: 0.0122 - accuracy: 0.9953 - val_loss: 0.1331 - val_accuracy: 0.9570\n",
      "Epoch 40/60\n",
      "96/96 [==============================] - 4s 44ms/step - loss: 0.0440 - accuracy: 0.9858 - val_loss: 0.5648 - val_accuracy: 0.8512\n",
      "Epoch 41/60\n",
      "96/96 [==============================] - 4s 45ms/step - loss: 0.0122 - accuracy: 0.9953 - val_loss: 0.1266 - val_accuracy: 0.9570\n",
      "Epoch 42/60\n",
      "96/96 [==============================] - 4s 43ms/step - loss: 0.0087 - accuracy: 0.9971 - val_loss: 0.1100 - val_accuracy: 0.9675\n",
      "Epoch 43/60\n",
      "96/96 [==============================] - 4s 44ms/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 0.1076 - val_accuracy: 0.9686\n",
      "Epoch 44/60\n",
      "96/96 [==============================] - 4s 45ms/step - loss: 0.0101 - accuracy: 0.9961 - val_loss: 0.0870 - val_accuracy: 0.9717\n",
      "Epoch 45/60\n",
      "96/96 [==============================] - 4s 43ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.0877 - val_accuracy: 0.9717\n",
      "Epoch 46/60\n",
      "96/96 [==============================] - 4s 42ms/step - loss: 0.0069 - accuracy: 0.9984 - val_loss: 0.2773 - val_accuracy: 0.9266\n",
      "Epoch 47/60\n",
      "96/96 [==============================] - 4s 44ms/step - loss: 0.0209 - accuracy: 0.9921 - val_loss: 0.3390 - val_accuracy: 0.9130\n",
      "Epoch 48/60\n",
      "96/96 [==============================] - 4s 44ms/step - loss: 0.0170 - accuracy: 0.9929 - val_loss: 0.4197 - val_accuracy: 0.9046\n",
      "Epoch 49/60\n",
      "96/96 [==============================] - 4s 44ms/step - loss: 0.0071 - accuracy: 0.9984 - val_loss: 0.2620 - val_accuracy: 0.9392\n",
      "Epoch 50/60\n",
      "96/96 [==============================] - 4s 42ms/step - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.1303 - val_accuracy: 0.9612\n",
      "Epoch 51/60\n",
      "96/96 [==============================] - 4s 44ms/step - loss: 0.0153 - accuracy: 0.9934 - val_loss: 0.2913 - val_accuracy: 0.9308\n",
      "Epoch 52/60\n",
      "96/96 [==============================] - 4s 45ms/step - loss: 0.0251 - accuracy: 0.9906 - val_loss: 0.2449 - val_accuracy: 0.9340\n",
      "Epoch 53/60\n",
      "96/96 [==============================] - 4s 43ms/step - loss: 0.0230 - accuracy: 0.9911 - val_loss: 0.1076 - val_accuracy: 0.9633\n",
      "Epoch 54/60\n",
      "96/96 [==============================] - 4s 43ms/step - loss: 0.0180 - accuracy: 0.9942 - val_loss: 0.1336 - val_accuracy: 0.9623\n",
      "Epoch 55/60\n",
      "96/96 [==============================] - 4s 45ms/step - loss: 0.0173 - accuracy: 0.9929 - val_loss: 0.4805 - val_accuracy: 0.9004\n",
      "Epoch 56/60\n",
      "96/96 [==============================] - 4s 44ms/step - loss: 0.0228 - accuracy: 0.9906 - val_loss: 0.2763 - val_accuracy: 0.9214\n",
      "Epoch 57/60\n",
      "96/96 [==============================] - 4s 43ms/step - loss: 0.0279 - accuracy: 0.9890 - val_loss: 0.0806 - val_accuracy: 0.9748\n",
      "Epoch 58/60\n",
      "96/96 [==============================] - 4s 43ms/step - loss: 0.0071 - accuracy: 0.9974 - val_loss: 0.0726 - val_accuracy: 0.9780\n",
      "Epoch 59/60\n",
      "96/96 [==============================] - 4s 46ms/step - loss: 0.0028 - accuracy: 0.9997 - val_loss: 0.0632 - val_accuracy: 0.9811\n",
      "Epoch 60/60\n",
      "96/96 [==============================] - 5s 47ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0677 - val_accuracy: 0.9811\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x21680775890>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=cnnmodel()\n",
    "model.fit(train_features,train_labels,epochs=60,batch_size=40,validation_data=(val_features,val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7396a1c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 8ms/step - loss: 0.0677 - accuracy: 0.9811\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06769640743732452, 0.9811320900917053]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(val_features,val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "55fe3671",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(val_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "289e3eb8-7320-4bf1-accf-1655414d3d5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on val_labely: 98.11%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Convert the list of predictions to a numpy array\n",
    "predictions_array = np.squeeze(np.array(predictions))\n",
    "\n",
    "# Round the predictions to get the predicted class (0 or 1)\n",
    "rounded_predictions = np.round(predictions_array).astype(int)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(val_labels, rounded_predictions)\n",
    "print(f\"Accuracy on val_labely: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "42b9f19d-7953-4682-99b7-62aaa91917f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[401  11]\n",
      " [  7 535]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9811320754716981"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(val_labels, rounded_predictions)\n",
    "print(cm)\n",
    "accuracy_score(val_labels, rounded_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
